{
  
    
        "post0": {
            "title": "Learner",
            "content": ". !pip install -Uqq fastbook import fastbook fastbook.setup_book() . |████████████████████████████████| 727kB 8.4MB/s |████████████████████████████████| 194kB 26.8MB/s |████████████████████████████████| 1.2MB 25.1MB/s |████████████████████████████████| 51kB 5.7MB/s |████████████████████████████████| 61kB 6.8MB/s |████████████████████████████████| 51kB 5.9MB/s Mounted at /content/gdrive . from fastai.vision.all import * from fastbook import * matplotlib.rc(&#39;image&#39;, cmap=&#39;Greys&#39;) . Beginning . def init_params(size, std=1.0): return (torch.randn(size)*std).requires_grad_() . weights = init_params((28*28,1)) bias = init_params(1) . path = untar_data(URLs.MNIST_SAMPLE) Path.BASE_PATH = path (path/&#39;train&#39;).ls() . (#2) [Path(&#39;train/3&#39;),Path(&#39;train/7&#39;)] . threes = (path/&#39;train&#39;/&#39;3&#39;).ls().sorted() sevens = (path/&#39;train&#39;/&#39;7&#39;).ls().sorted() . seven_tensors = [tensor(Image.open(o)) for o in sevens] three_tensors = [tensor(Image.open(o)) for o in threes] len(three_tensors),len(seven_tensors) show_image(three_tensors[1]); .",
            "url": "https://frederikknudsen.github.io/Fastpage/2021/04/26/_03_02_Learner.html",
            "relUrl": "/2021/04/26/_03_02_Learner.html",
            "date": " • Apr 26, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Hotdog Classifier Final",
            "content": "!pip install -Uqq fastbook import fastbook fastbook.setup_book() from fastbook import * from fastai.vision.widgets import * . |████████████████████████████████| 727kB 5.3MB/s |████████████████████████████████| 1.2MB 9.1MB/s |████████████████████████████████| 51kB 6.1MB/s |████████████████████████████████| 194kB 16.3MB/s |████████████████████████████████| 61kB 7.5MB/s . path = Path() learn_inf = load_learner(path/&#39;HotdogExport.pkl&#39;, cpu=True) btn_upload = widgets.FileUpload() out_pl = widgets.Output() lbl_pred = widgets.Label() . def on_data_change(change): lbl_pred.value = &#39;&#39; img = PILImage.create(btn_upload.data[-1]) out_pl.clear_output() with out_pl: display(img.to_thumb(128,128)) pred,pred_idx,probs = learn_inf.predict(img) lbl_pred.value = f&#39;Prediction: {pred}; Probability: {probs[pred_idx]:.04f}&#39; . btn_upload.observe(on_data_change, names=[&#39;data&#39;]) . display(VBox([widgets.Label(&#39;Is it really a hotdog?&#39;), btn_upload, out_pl, lbl_pred])) .",
            "url": "https://frederikknudsen.github.io/Fastpage/2021/04/26/_02_21_Hotdog_Classifier_Final.html",
            "relUrl": "/2021/04/26/_02_21_Hotdog_Classifier_Final.html",
            "date": " • Apr 26, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Hotdog Classifier",
            "content": ". Opsætning af FastAI . key = os.environ.get(&#39;AZURE_SEARCH_KEY&#39;, &#39;88f816fb74d147e08b211baf0cceebbb&#39;) . bear_types = &#39;hotdog&#39;, &#39;random&#39; path = Path(&#39;hotdogs&#39;) . if not path.exists(): path.mkdir() for o in bear_types: dest = (path/o) dest.mkdir(exist_ok=True) results = search_images_bing(key, f&#39;{o}&#39;) download_images(dest, urls=results.attrgot(&#39;contentUrl&#39;)) . fns = get_image_files(path) failed = verify_images(fns) failed . (#8) [Path(&#39;hotdogs/random/00000138.png&#39;),Path(&#39;hotdogs/random/00000073.jpg&#39;),Path(&#39;hotdogs/random/00000080.jpg&#39;),Path(&#39;hotdogs/hotdog/00000099.png&#39;),Path(&#39;hotdogs/hotdog/00000014.jpg&#39;),Path(&#39;hotdogs/hotdog/00000045.jpg&#39;),Path(&#39;hotdogs/hotdog/00000007.jpg&#39;),Path(&#39;hotdogs/hotdog/00000050.jpeg&#39;)] . failed.map(Path.unlink); . # What kinds of data we are working with # How to get the list of items # How to label these items # How to create the validation set bears = DataBlock( blocks=(ImageBlock, CategoryBlock), get_items=get_image_files, splitter=RandomSplitter(valid_pct=0.2, seed=42), get_y=parent_label, item_tfms=Resize(128)) . dls = bears.dataloaders(path) . dls.valid.show_batch(max_n=4, nrows=1) . /usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images &#34;Palette images with Transparency expressed in bytes should be &#34; . validLossList = [] class PrintLoss(Callback): def after_epoch(self): validLossList.append(self.learn.loss) if len(validLossList) &gt;= 2: if validLossList[-2] &gt; validLossList[-1]: self.learn.lr_find() print(self.learn.recorder.min_grad_lr) # self.learn.pred = learn.recorder.min_grad_lr # learn.lr_find(stop_div=False, num_it=200) # print(learn.recorder.plot(suggestion=True)) return True . bears = bears.new( item_tfms=RandomResizedCrop(224, min_scale=0.5), batch_tfms=aug_transforms()) dls = bears.dataloaders(path) . learn = cnn_learner(dls, resnet18, metrics=error_rate) learn.fit(3, cbs=PrintLoss()) . . 33.33% [1/3 00:12&lt;00:24] epoch train_loss valid_loss error_rate time . 0 | 0.710942 | 2.795571 | 0.566038 | 00:12 | . . 100.00% [1/1 00:02&lt;00:00] &lt;/div&gt; &lt;/div&gt; /usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images &#34;Palette images with Transparency expressed in bytes should be &#34; /usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images &#34;Palette images with Transparency expressed in bytes should be &#34; /usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images &#34;Palette images with Transparency expressed in bytes should be &#34; /usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images &#34;Palette images with Transparency expressed in bytes should be &#34; /usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images &#34;Palette images with Transparency expressed in bytes should be &#34; /usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images &#34;Palette images with Transparency expressed in bytes should be &#34; . . 0.00% [0/34 00:00&lt;00:00] . 0.00% [0/1 00:00&lt;00:00] /usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images &#34;Palette images with Transparency expressed in bytes should be &#34; . . 2.94% [1/34 00:09&lt;05:05] . 0.00% [0/1 00:00&lt;00:00] /usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images &#34;Palette images with Transparency expressed in bytes should be &#34; /usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images &#34;Palette images with Transparency expressed in bytes should be &#34; /usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images &#34;Palette images with Transparency expressed in bytes should be &#34; /usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images &#34;Palette images with Transparency expressed in bytes should be &#34; . . 0.00% [0/34 00:00&lt;00:00] . 33.33% [1/3 00:04&lt;00:09] /usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images &#34;Palette images with Transparency expressed in bytes should be &#34; . KeyboardInterrupt Traceback (most recent call last) &lt;ipython-input-76-a25b594d4937&gt; in &lt;module&gt;() 1 learn = cnn_learner(dls, resnet18, metrics=error_rate) -&gt; 2 learn.fit(3, cbs=PrintLoss()) /usr/local/lib/python3.7/dist-packages/fastai/learner.py in fit(self, n_epoch, lr, wd, cbs, reset_opt) 210 self.opt.set_hypers(lr=self.lr if lr is None else lr) 211 self.n_epoch = n_epoch --&gt; 212 self._with_events(self._do_fit, &#39;fit&#39;, CancelFitException, self._end_cleanup) 213 214 def _end_cleanup(self): self.dl,self.xb,self.yb,self.pred,self.loss = None,(None,),(None,),None,None /usr/local/lib/python3.7/dist-packages/fastai/learner.py in _with_events(self, f, event_type, ex, final) 158 159 def _with_events(self, f, event_type, ex, final=noop): --&gt; 160 try: self(f&#39;before_{event_type}&#39;); f() 161 except ex: self(f&#39;after_cancel_{event_type}&#39;) 162 self(f&#39;after_{event_type}&#39;); final() /usr/local/lib/python3.7/dist-packages/fastai/learner.py in _do_fit(self) 201 for epoch in range(self.n_epoch): 202 self.epoch=epoch --&gt; 203 self._with_events(self._do_epoch, &#39;epoch&#39;, CancelEpochException) 204 205 def fit(self, n_epoch, lr=None, wd=None, cbs=None, reset_opt=False): /usr/local/lib/python3.7/dist-packages/fastai/learner.py in _with_events(self, f, event_type, ex, final) 160 try: self(f&#39;before_{event_type}&#39;); f() 161 except ex: self(f&#39;after_cancel_{event_type}&#39;) --&gt; 162 self(f&#39;after_{event_type}&#39;); final() 163 164 def all_batches(self): /usr/local/lib/python3.7/dist-packages/fastai/learner.py in __call__(self, event_name) 139 140 def ordered_cbs(self, event): return [cb for cb in self.cbs.sorted(&#39;order&#39;) if hasattr(cb, event)] --&gt; 141 def __call__(self, event_name): L(event_name).map(self._call_one) 142 143 def _call_one(self, event_name): /usr/local/lib/python3.7/dist-packages/fastcore/foundation.py in map(self, f, gen, *args, **kwargs) 152 def range(cls, a, b=None, step=None): return cls(range_of(a, b=b, step=step)) 153 --&gt; 154 def map(self, f, *args, gen=False, **kwargs): return self._new(map_ex(self, f, *args, gen=gen, **kwargs)) 155 def argwhere(self, f, negate=False, **kwargs): return self._new(argwhere(self, f, negate, **kwargs)) 156 def filter(self, f=noop, negate=False, gen=False, **kwargs): /usr/local/lib/python3.7/dist-packages/fastcore/basics.py in map_ex(iterable, f, gen, *args, **kwargs) 664 res = map(g, iterable) 665 if gen: return res --&gt; 666 return list(res) 667 668 # Cell /usr/local/lib/python3.7/dist-packages/fastcore/basics.py in __call__(self, *args, **kwargs) 649 if isinstance(v,_Arg): kwargs[k] = args.pop(v.i) 650 fargs = [args[x.i] if isinstance(x, _Arg) else x for x in self.pargs] + args[self.maxi+1:] --&gt; 651 return self.func(*fargs, **kwargs) 652 653 # Cell /usr/local/lib/python3.7/dist-packages/fastai/learner.py in _call_one(self, event_name) 143 def _call_one(self, event_name): 144 if not hasattr(event, event_name): raise Exception(f&#39;missing {event_name}&#39;) --&gt; 145 for cb in self.cbs.sorted(&#39;order&#39;): cb(event_name) 146 147 def _bn_bias_state(self, with_bias): return norm_bias_params(self.model, with_bias).map(self.opt.state) /usr/local/lib/python3.7/dist-packages/fastai/callback/core.py in __call__(self, event_name) 42 (self.run_valid and not getattr(self, &#39;training&#39;, False))) 43 res = None &gt; 44 if self.run and _run: res = getattr(self, event_name, noop)() 45 if event_name==&#39;after_fit&#39;: self.run=True #Reset self.run to True at each end of fit 46 return res &lt;ipython-input-75-40879685eef4&gt; in after_epoch(self) 6 if len(validLossList) &gt;= 2: 7 if validLossList[-2] &gt; validLossList[-1]: -&gt; 8 self.learn.lr_find() 9 print(self.learn.recorder.min_grad_lr) 10 # self.learn.pred = learn.recorder.min_grad_lr /usr/local/lib/python3.7/dist-packages/fastai/callback/schedule.py in lr_find(self, start_lr, end_lr, num_it, stop_div, show_plot, suggestions) 220 n_epoch = num_it//len(self.dls.train) + 1 221 cb=LRFinder(start_lr=start_lr, end_lr=end_lr, num_it=num_it, stop_div=stop_div) --&gt; 222 with self.no_logging(): self.fit(n_epoch, cbs=cb) 223 if show_plot: self.recorder.plot_lr_find() 224 if suggestions: /usr/local/lib/python3.7/dist-packages/fastai/learner.py in fit(self, n_epoch, lr, wd, cbs, reset_opt) 210 self.opt.set_hypers(lr=self.lr if lr is None else lr) 211 self.n_epoch = n_epoch --&gt; 212 self._with_events(self._do_fit, &#39;fit&#39;, CancelFitException, self._end_cleanup) 213 214 def _end_cleanup(self): self.dl,self.xb,self.yb,self.pred,self.loss = None,(None,),(None,),None,None /usr/local/lib/python3.7/dist-packages/fastai/learner.py in _with_events(self, f, event_type, ex, final) 158 159 def _with_events(self, f, event_type, ex, final=noop): --&gt; 160 try: self(f&#39;before_{event_type}&#39;); f() 161 except ex: self(f&#39;after_cancel_{event_type}&#39;) 162 self(f&#39;after_{event_type}&#39;); final() /usr/local/lib/python3.7/dist-packages/fastai/learner.py in _do_fit(self) 201 for epoch in range(self.n_epoch): 202 self.epoch=epoch --&gt; 203 self._with_events(self._do_epoch, &#39;epoch&#39;, CancelEpochException) 204 205 def fit(self, n_epoch, lr=None, wd=None, cbs=None, reset_opt=False): /usr/local/lib/python3.7/dist-packages/fastai/learner.py in _with_events(self, f, event_type, ex, final) 160 try: self(f&#39;before_{event_type}&#39;); f() 161 except ex: self(f&#39;after_cancel_{event_type}&#39;) --&gt; 162 self(f&#39;after_{event_type}&#39;); final() 163 164 def all_batches(self): /usr/local/lib/python3.7/dist-packages/fastai/learner.py in __call__(self, event_name) 139 140 def ordered_cbs(self, event): return [cb for cb in self.cbs.sorted(&#39;order&#39;) if hasattr(cb, event)] --&gt; 141 def __call__(self, event_name): L(event_name).map(self._call_one) 142 143 def _call_one(self, event_name): /usr/local/lib/python3.7/dist-packages/fastcore/foundation.py in map(self, f, gen, *args, **kwargs) 152 def range(cls, a, b=None, step=None): return cls(range_of(a, b=b, step=step)) 153 --&gt; 154 def map(self, f, *args, gen=False, **kwargs): return self._new(map_ex(self, f, *args, gen=gen, **kwargs)) 155 def argwhere(self, f, negate=False, **kwargs): return self._new(argwhere(self, f, negate, **kwargs)) 156 def filter(self, f=noop, negate=False, gen=False, **kwargs): /usr/local/lib/python3.7/dist-packages/fastcore/basics.py in map_ex(iterable, f, gen, *args, **kwargs) 664 res = map(g, iterable) 665 if gen: return res --&gt; 666 return list(res) 667 668 # Cell /usr/local/lib/python3.7/dist-packages/fastcore/basics.py in __call__(self, *args, **kwargs) 649 if isinstance(v,_Arg): kwargs[k] = args.pop(v.i) 650 fargs = [args[x.i] if isinstance(x, _Arg) else x for x in self.pargs] + args[self.maxi+1:] --&gt; 651 return self.func(*fargs, **kwargs) 652 653 # Cell /usr/local/lib/python3.7/dist-packages/fastai/learner.py in _call_one(self, event_name) 143 def _call_one(self, event_name): 144 if not hasattr(event, event_name): raise Exception(f&#39;missing {event_name}&#39;) --&gt; 145 for cb in self.cbs.sorted(&#39;order&#39;): cb(event_name) 146 147 def _bn_bias_state(self, with_bias): return norm_bias_params(self.model, with_bias).map(self.opt.state) /usr/local/lib/python3.7/dist-packages/fastai/callback/core.py in __call__(self, event_name) 42 (self.run_valid and not getattr(self, &#39;training&#39;, False))) 43 res = None &gt; 44 if self.run and _run: res = getattr(self, event_name, noop)() 45 if event_name==&#39;after_fit&#39;: self.run=True #Reset self.run to True at each end of fit 46 return res &lt;ipython-input-75-40879685eef4&gt; in after_epoch(self) 6 if len(validLossList) &gt;= 2: 7 if validLossList[-2] &gt; validLossList[-1]: -&gt; 8 self.learn.lr_find() 9 print(self.learn.recorder.min_grad_lr) 10 # self.learn.pred = learn.recorder.min_grad_lr /usr/local/lib/python3.7/dist-packages/fastai/callback/schedule.py in lr_find(self, start_lr, end_lr, num_it, stop_div, show_plot, suggestions) 220 n_epoch = num_it//len(self.dls.train) + 1 221 cb=LRFinder(start_lr=start_lr, end_lr=end_lr, num_it=num_it, stop_div=stop_div) --&gt; 222 with self.no_logging(): self.fit(n_epoch, cbs=cb) 223 if show_plot: self.recorder.plot_lr_find() 224 if suggestions: /usr/local/lib/python3.7/dist-packages/fastai/learner.py in fit(self, n_epoch, lr, wd, cbs, reset_opt) 210 self.opt.set_hypers(lr=self.lr if lr is None else lr) 211 self.n_epoch = n_epoch --&gt; 212 self._with_events(self._do_fit, &#39;fit&#39;, CancelFitException, self._end_cleanup) 213 214 def _end_cleanup(self): self.dl,self.xb,self.yb,self.pred,self.loss = None,(None,),(None,),None,None /usr/local/lib/python3.7/dist-packages/fastai/learner.py in _with_events(self, f, event_type, ex, final) 158 159 def _with_events(self, f, event_type, ex, final=noop): --&gt; 160 try: self(f&#39;before_{event_type}&#39;); f() 161 except ex: self(f&#39;after_cancel_{event_type}&#39;) 162 self(f&#39;after_{event_type}&#39;); final() /usr/local/lib/python3.7/dist-packages/fastai/learner.py in _do_fit(self) 201 for epoch in range(self.n_epoch): 202 self.epoch=epoch --&gt; 203 self._with_events(self._do_epoch, &#39;epoch&#39;, CancelEpochException) 204 205 def fit(self, n_epoch, lr=None, wd=None, cbs=None, reset_opt=False): /usr/local/lib/python3.7/dist-packages/fastai/learner.py in _with_events(self, f, event_type, ex, final) 160 try: self(f&#39;before_{event_type}&#39;); f() 161 except ex: self(f&#39;after_cancel_{event_type}&#39;) --&gt; 162 self(f&#39;after_{event_type}&#39;); final() 163 164 def all_batches(self): /usr/local/lib/python3.7/dist-packages/fastai/learner.py in __call__(self, event_name) 139 140 def ordered_cbs(self, event): return [cb for cb in self.cbs.sorted(&#39;order&#39;) if hasattr(cb, event)] --&gt; 141 def __call__(self, event_name): L(event_name).map(self._call_one) 142 143 def _call_one(self, event_name): /usr/local/lib/python3.7/dist-packages/fastcore/foundation.py in map(self, f, gen, *args, **kwargs) 152 def range(cls, a, b=None, step=None): return cls(range_of(a, b=b, step=step)) 153 --&gt; 154 def map(self, f, *args, gen=False, **kwargs): return self._new(map_ex(self, f, *args, gen=gen, **kwargs)) 155 def argwhere(self, f, negate=False, **kwargs): return self._new(argwhere(self, f, negate, **kwargs)) 156 def filter(self, f=noop, negate=False, gen=False, **kwargs): /usr/local/lib/python3.7/dist-packages/fastcore/basics.py in map_ex(iterable, f, gen, *args, **kwargs) 664 res = map(g, iterable) 665 if gen: return res --&gt; 666 return list(res) 667 668 # Cell /usr/local/lib/python3.7/dist-packages/fastcore/basics.py in __call__(self, *args, **kwargs) 649 if isinstance(v,_Arg): kwargs[k] = args.pop(v.i) 650 fargs = [args[x.i] if isinstance(x, _Arg) else x for x in self.pargs] + args[self.maxi+1:] --&gt; 651 return self.func(*fargs, **kwargs) 652 653 # Cell /usr/local/lib/python3.7/dist-packages/fastai/learner.py in _call_one(self, event_name) 143 def _call_one(self, event_name): 144 if not hasattr(event, event_name): raise Exception(f&#39;missing {event_name}&#39;) --&gt; 145 for cb in self.cbs.sorted(&#39;order&#39;): cb(event_name) 146 147 def _bn_bias_state(self, with_bias): return norm_bias_params(self.model, with_bias).map(self.opt.state) /usr/local/lib/python3.7/dist-packages/fastai/callback/core.py in __call__(self, event_name) 42 (self.run_valid and not getattr(self, &#39;training&#39;, False))) 43 res = None &gt; 44 if self.run and _run: res = getattr(self, event_name, noop)() 45 if event_name==&#39;after_fit&#39;: self.run=True #Reset self.run to True at each end of fit 46 return res &lt;ipython-input-75-40879685eef4&gt; in after_epoch(self) 6 if len(validLossList) &gt;= 2: 7 if validLossList[-2] &gt; validLossList[-1]: -&gt; 8 self.learn.lr_find() 9 print(self.learn.recorder.min_grad_lr) 10 # self.learn.pred = learn.recorder.min_grad_lr /usr/local/lib/python3.7/dist-packages/fastai/callback/schedule.py in lr_find(self, start_lr, end_lr, num_it, stop_div, show_plot, suggestions) 220 n_epoch = num_it//len(self.dls.train) + 1 221 cb=LRFinder(start_lr=start_lr, end_lr=end_lr, num_it=num_it, stop_div=stop_div) --&gt; 222 with self.no_logging(): self.fit(n_epoch, cbs=cb) 223 if show_plot: self.recorder.plot_lr_find() 224 if suggestions: /usr/local/lib/python3.7/dist-packages/fastai/learner.py in fit(self, n_epoch, lr, wd, cbs, reset_opt) 210 self.opt.set_hypers(lr=self.lr if lr is None else lr) 211 self.n_epoch = n_epoch --&gt; 212 self._with_events(self._do_fit, &#39;fit&#39;, CancelFitException, self._end_cleanup) 213 214 def _end_cleanup(self): self.dl,self.xb,self.yb,self.pred,self.loss = None,(None,),(None,),None,None /usr/local/lib/python3.7/dist-packages/fastai/learner.py in _with_events(self, f, event_type, ex, final) 158 159 def _with_events(self, f, event_type, ex, final=noop): --&gt; 160 try: self(f&#39;before_{event_type}&#39;); f() 161 except ex: self(f&#39;after_cancel_{event_type}&#39;) 162 self(f&#39;after_{event_type}&#39;); final() /usr/local/lib/python3.7/dist-packages/fastai/learner.py in _do_fit(self) 201 for epoch in range(self.n_epoch): 202 self.epoch=epoch --&gt; 203 self._with_events(self._do_epoch, &#39;epoch&#39;, CancelEpochException) 204 205 def fit(self, n_epoch, lr=None, wd=None, cbs=None, reset_opt=False): /usr/local/lib/python3.7/dist-packages/fastai/learner.py in _with_events(self, f, event_type, ex, final) 158 159 def _with_events(self, f, event_type, ex, final=noop): --&gt; 160 try: self(f&#39;before_{event_type}&#39;); f() 161 except ex: self(f&#39;after_cancel_{event_type}&#39;) 162 self(f&#39;after_{event_type}&#39;); final() /usr/local/lib/python3.7/dist-packages/fastai/learner.py in _do_epoch(self) 195 196 def _do_epoch(self): --&gt; 197 self._do_epoch_train() 198 self._do_epoch_validate() 199 /usr/local/lib/python3.7/dist-packages/fastai/learner.py in _do_epoch_train(self) 187 def _do_epoch_train(self): 188 self.dl = self.dls.train --&gt; 189 self._with_events(self.all_batches, &#39;train&#39;, CancelTrainException) 190 191 def _do_epoch_validate(self, ds_idx=1, dl=None): /usr/local/lib/python3.7/dist-packages/fastai/learner.py in _with_events(self, f, event_type, ex, final) 158 159 def _with_events(self, f, event_type, ex, final=noop): --&gt; 160 try: self(f&#39;before_{event_type}&#39;); f() 161 except ex: self(f&#39;after_cancel_{event_type}&#39;) 162 self(f&#39;after_{event_type}&#39;); final() /usr/local/lib/python3.7/dist-packages/fastai/learner.py in all_batches(self) 164 def all_batches(self): 165 self.n_iter = len(self.dl) --&gt; 166 for o in enumerate(self.dl): self.one_batch(*o) 167 168 def _do_one_batch(self): /usr/local/lib/python3.7/dist-packages/fastai/data/load.py in __iter__(self) 107 self.before_iter() 108 self.__idxs=self.get_idxs() # called in context of main process (not workers/subprocesses) --&gt; 109 for b in _loaders[self.fake_l.num_workers==0](self.fake_l): 110 # fix issue 2899. If the process start method isn&#39;t fork, the data will be copied to cuda in learner one_batch. 111 if self.device is not None and multiprocessing.get_start_method().lower() == &#34;fork&#34;: /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py in __next__(self) 433 if self._sampler_iter is None: 434 self._reset() --&gt; 435 data = self._next_data() 436 self._num_yielded += 1 437 if self._dataset_kind == _DatasetKind.Iterable and /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py in _next_data(self) 1066 1067 assert not self._shutdown and self._tasks_outstanding &gt; 0 -&gt; 1068 idx, data = self._get_data() 1069 self._tasks_outstanding -= 1 1070 if self._dataset_kind == _DatasetKind.Iterable: /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py in _get_data(self) 1032 else: 1033 while True: -&gt; 1034 success, data = self._try_get_data() 1035 if success: 1036 return data /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py in _try_get_data(self, timeout) 870 # (bool: whether successfully get data, any: data if successful else None) 871 try: --&gt; 872 data = self._data_queue.get(timeout=timeout) 873 return (True, data) 874 except Exception as e: /usr/lib/python3.7/multiprocessing/queues.py in get(self, block, timeout) 102 if block: 103 timeout = deadline - time.monotonic() --&gt; 104 if not self._poll(timeout): 105 raise Empty 106 elif not self._poll(): /usr/lib/python3.7/multiprocessing/connection.py in poll(self, timeout) 255 self._check_closed() 256 self._check_readable() --&gt; 257 return self._poll(timeout) 258 259 def __enter__(self): /usr/lib/python3.7/multiprocessing/connection.py in _poll(self, timeout) 412 413 def _poll(self, timeout): --&gt; 414 r = wait([self], timeout) 415 return bool(r) 416 /usr/lib/python3.7/multiprocessing/connection.py in wait(object_list, timeout) 919 920 while True: --&gt; 921 ready = selector.select(timeout) 922 if ready: 923 return [key.fileobj for (key, events) in ready] /usr/lib/python3.7/selectors.py in select(self, timeout) 413 ready = [] 414 try: --&gt; 415 fd_event_list = self._selector.poll(timeout) 416 except InterruptedError: 417 return ready KeyboardInterrupt: . &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; interp = ClassificationInterpretation.from_learner(learn) interp.plot_confusion_matrix() . interp.plot_top_losses(5, nrows=1) . cleaner = ImageClassifierCleaner(learn) . Eksportering af trænet model . learn.export() path = Path() path.ls(file_exts=&#39;.pkl&#39;) . APP . learn_inf = load_learner(path/&#39;export.pkl&#39;) . btn_upload = widgets.FileUpload() btn_upload . img = PILImage.create(btn_upload.data[-1]) . out_pl = widgets.Output() out_pl.clear_output() with out_pl: display(img.to_thumb(128,128)) out_pl . pred,pred_idx,probs = learn_inf.predict(img) lbl_pred = widgets.Label() lbl_pred.value = f&#39;Prediction: {pred}; Probability: {probs[pred_idx]:.04f}&#39; lbl_pred . btn_run = widgets.Button(description=&#39;Classify&#39;) . def on_click_classify(change): img = PILImage.create(btn_upload.data[-1]) out_pl.clear_output() with out_pl: display(img.to_thumb(128,128)) pred,pred_idx,probs = learn_inf.predict(img) lbl_pred.value = f&#39;Prediction: {pred}; Probability: {probs[pred_idx]:.04f}&#39; btn_run.on_click(on_click_classify) . VBox([widgets.Label(&#39;Select your hotdog!&#39;), btn_upload, btn_run, out_pl, lbl_pred]) . &lt;/div&gt; .",
            "url": "https://frederikknudsen.github.io/Fastpage/2021/04/26/_02_16_Hotdog_Classifier.html",
            "relUrl": "/2021/04/26/_02_16_Hotdog_Classifier.html",
            "date": " • Apr 26, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Chapter 5 Optimization",
            "content": ". !pip install -Uqq fastbook import fastbook fastbook.setup_book() . from fastbook import * .",
            "url": "https://frederikknudsen.github.io/Fastpage/2021/03/09/Chapter5_Optimization.html",
            "relUrl": "/2021/03/09/Chapter5_Optimization.html",
            "date": " • Mar 9, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "Hotdog Classifier",
            "content": "Opsætning af FastAI . key = os.environ.get(&#39;AZURE_SEARCH_KEY&#39;, &#39;88f816fb74d147e08b211baf0cceebbb&#39;) . bear_types = &#39;hotdog&#39;, &#39;random&#39; path = Path(&#39;hotdogs&#39;) . if not path.exists(): path.mkdir() for o in bear_types: dest = (path/o) dest.mkdir(exist_ok=True) results = search_images_bing(key, f&#39;{o}&#39;) download_images(dest, urls=results.attrgot(&#39;contentUrl&#39;)) . fns = get_image_files(path) failed = verify_images(fns) failed . (#0) [] . failed.map(Path.unlink); . # What kinds of data we are working with # How to get the list of items # How to label these items # How to create the validation set bears = DataBlock( blocks=(ImageBlock, CategoryBlock), get_items=get_image_files, splitter=RandomSplitter(valid_pct=0.2, seed=42), get_y=parent_label, item_tfms=Resize(128)) . dls = bears.dataloaders(path) . dls.valid.show_batch(max_n=4, nrows=1) . bears = bears.new( item_tfms=RandomResizedCrop(224, min_scale=0.5), batch_tfms=aug_transforms()) dls = bears.dataloaders(path) . learn = cnn_learner(dls, resnet18, metrics=error_rate) learn.fine_tune(4) . epoch train_loss valid_loss error_rate time . 0 | 1.353194 | 2.531444 | 0.589286 | 00:53 | . /usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images &#34;Palette images with Transparency expressed in bytes should be &#34; /usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images &#34;Palette images with Transparency expressed in bytes should be &#34; . epoch train_loss valid_loss error_rate time . 0 | 0.211472 | 0.479127 | 0.196429 | 01:10 | . 1 | 0.151953 | 0.067017 | 0.017857 | 01:10 | . 2 | 0.104865 | 0.125545 | 0.035714 | 01:12 | . 3 | 0.079182 | 0.227735 | 0.053571 | 01:11 | . /usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images &#34;Palette images with Transparency expressed in bytes should be &#34; /usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images &#34;Palette images with Transparency expressed in bytes should be &#34; /usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images &#34;Palette images with Transparency expressed in bytes should be &#34; /usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images &#34;Palette images with Transparency expressed in bytes should be &#34; /usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images &#34;Palette images with Transparency expressed in bytes should be &#34; /usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images &#34;Palette images with Transparency expressed in bytes should be &#34; /usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images &#34;Palette images with Transparency expressed in bytes should be &#34; /usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images &#34;Palette images with Transparency expressed in bytes should be &#34; . interp = ClassificationInterpretation.from_learner(learn) interp.plot_confusion_matrix() . interp.plot_top_losses(5, nrows=1) . cleaner = ImageClassifierCleaner(learn) . /usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images &#34;Palette images with Transparency expressed in bytes should be &#34; /usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images &#34;Palette images with Transparency expressed in bytes should be &#34; . Eksportering af trænet model . learn.export() path = Path() path.ls(file_exts=&#39;.pkl&#39;) . (#1) [Path(&#39;export.pkl&#39;)] . APP . learn_inf = load_learner(path/&#39;export.pkl&#39;) . btn_upload = widgets.FileUpload() btn_upload . img = PILImage.create(btn_upload.data[-1]) . out_pl = widgets.Output() out_pl.clear_output() with out_pl: display(img.to_thumb(128,128)) out_pl . pred,pred_idx,probs = learn_inf.predict(img) lbl_pred = widgets.Label() lbl_pred.value = f&#39;Prediction: {pred}; Probability: {probs[pred_idx]:.04f}&#39; lbl_pred . btn_run = widgets.Button(description=&#39;Classify&#39;) . def on_click_classify(change): img = PILImage.create(btn_upload.data[-1]) out_pl.clear_output() with out_pl: display(img.to_thumb(128,128)) pred,pred_idx,probs = learn_inf.predict(img) lbl_pred.value = f&#39;Prediction: {pred}; Probability: {probs[pred_idx]:.04f}&#39; btn_run.on_click(on_click_classify) . VBox([widgets.Label(&#39;Select your hotdog!&#39;), btn_upload, btn_run, out_pl, lbl_pred]) .",
            "url": "https://frederikknudsen.github.io/Fastpage/2021/02/16/Hotdog-Classifier.html",
            "relUrl": "/2021/02/16/Hotdog-Classifier.html",
            "date": " • Feb 16, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://frederikknudsen.github.io/Fastpage/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://frederikknudsen.github.io/Fastpage/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://frederikknudsen.github.io/Fastpage/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}